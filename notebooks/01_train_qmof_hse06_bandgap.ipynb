{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Coarse-Grained Crystal Graph Neural Network ($CG^2$-Net) for band gap prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Download data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we show how the coarse-grained crystal graph network can be utilized to quantitatively reproduce DFT-calculated band gap of metal-organic frameworks (MOFs). First, we download [the Quantum MOF (QMOF) database](https://github.com/Andrew-S-Rosen/QMOF), which is used as a source of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import urllib\n",
    "import zipfile\n",
    "\n",
    "\n",
    "urllib.request.urlretrieve(\n",
    "    \"https://figshare.com/ndownloader/files/31713017\", \"qmof_database.zip\"\n",
    ")\n",
    "with zipfile.ZipFile(\"qmof_database.zip\", \"r\") as zip_ref:\n",
    "    zip_ref.extractall()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we load data from two JSON files, containing (among many other things) information on MOF crystal structures and target property values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "\n",
    "with open(\"qmof_database/qmof.json\") as f:\n",
    "    qmof = json.load(f)\n",
    "with open(\"qmof_database/qmof_structure_data.json\") as f:\n",
    "    struct_data = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Prepare coarse-grained crystal graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We iterate through `struct_data` and `qmof` lists to form two new lists (`graphs` and `labels`), which contain coarse-grained crystal graphs in the form of [`dgl.heterograph.DGLHeteroGraph`](https://docs.dgl.ai/en/0.9.x/_modules/dgl/heterograph.html) entities and float-type HSE06 band gaps, respectively. MOFs with potentially problematic linkers (e.g., containing pentavalent carbon or boron) are excluded from consideration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "qmof-ec9d083 Explicit valence for atom # 6 B, 5, is greater than permitted\n",
      "qmof-1a0c62d Explicit valence for atom # 4 C, 5, is greater than permitted\n",
      "qmof-e9351eb Explicit valence for atom # 6 B, 5, is greater than permitted\n",
      "qmof-ea0f641 Explicit valence for atom # 6 B, 5, is greater than permitted\n",
      "qmof-abf5294 Explicit valence for atom # 6 B, 5, is greater than permitted\n",
      "qmof-509d624 Explicit valence for atom # 6 B, 5, is greater than permitted\n",
      "qmof-6bc32fd Explicit valence for atom # 1 B, 5, is greater than permitted\n",
      "qmof-cadb719 Explicit valence for atom # 3 C, 5, is greater than permitted\n",
      "qmof-b78b0ad Explicit valence for atom # 3 C, 5, is greater than permitted\n",
      "qmof-cd46c95 Explicit valence for atom # 9 B, 5, is greater than permitted\n",
      "qmof-00a7fd4 Explicit valence for atom # 4 B, 5, is greater than permitted\n",
      "qmof-9d2522c Explicit valence for atom # 2 B, 5, is greater than permitted\n",
      "qmof-ca3f908 Explicit valence for atom # 1 B, 5, is greater than permitted\n",
      "qmof-5bcb068 Explicit valence for atom # 4 C, 5, is greater than permitted\n",
      "qmof-8ffd817 Explicit valence for atom # 13 C, 5, is greater than permitted\n",
      "qmof-363bce5 Explicit valence for atom # 4 B, 5, is greater than permitted\n",
      "qmof-40ada08 Explicit valence for atom # 1 B, 5, is greater than permitted\n",
      "qmof-272dfc1 Explicit valence for atom # 5 C, 5, is greater than permitted\n",
      "qmof-b24bd16 Explicit valence for atom # 1 B, 5, is greater than permitted\n",
      "qmof-4fa1780 Explicit valence for atom # 2 B, 5, is greater than permitted\n",
      "qmof-e0c96d6 Explicit valence for atom # 4 C, 5, is greater than permitted\n",
      "qmof-dfe761c Explicit valence for atom # 4 B, 5, is greater than permitted\n",
      "qmof-2e677ab Explicit valence for atom # 1 B, 5, is greater than permitted\n",
      "qmof-0f0c1d0 Explicit valence for atom # 4 B, 5, is greater than permitted\n",
      "qmof-f61cb8f Explicit valence for atom # 6 C, 5, is greater than permitted\n",
      "qmof-113f870 Explicit valence for atom # 3 C, 5, is greater than permitted\n",
      "qmof-baa9e72 Explicit valence for atom # 1 B, 5, is greater than permitted\n",
      "qmof-40981b9 Explicit valence for atom # 9 B, 5, is greater than permitted\n",
      "qmof-dd89c20 Explicit valence for atom # 8 B, 5, is greater than permitted\n",
      "qmof-3435b39 Explicit valence for atom # 6 C, 5, is greater than permitted\n",
      "qmof-76d822e Explicit valence for atom # 4 C, 5, is greater than permitted\n",
      "qmof-23c6559 Explicit valence for atom # 1 B, 5, is greater than permitted\n",
      "qmof-380359a Explicit valence for atom # 1 B, 5, is greater than permitted\n",
      "qmof-69c76a6 Explicit valence for atom # 6 B, 5, is greater than permitted\n",
      "qmof-e686033 Explicit valence for atom # 1 B, 5, is greater than permitted\n",
      "qmof-90bddf0 Explicit valence for atom # 3 B, 5, is greater than permitted\n",
      "qmof-27e4fe7 Explicit valence for atom # 8 B, 5, is greater than permitted\n",
      "qmof-2e79c69 Explicit valence for atom # 3 B, 5, is greater than permitted\n",
      "qmof-c6a024f Explicit valence for atom # 1 B, 5, is greater than permitted\n",
      "qmof-e4e7c8a Explicit valence for atom # 1 B, 5, is greater than permitted\n",
      "qmof-857f34a Explicit valence for atom # 4 B, 5, is greater than permitted\n",
      "qmof-4c838aa Explicit valence for atom # 6 B, 5, is greater than permitted\n",
      "qmof-6c0cc55 Explicit valence for atom # 8 B, 5, is greater than permitted\n",
      "qmof-44f590d Explicit valence for atom # 21 B, 5, is greater than permitted\n",
      "qmof-61b7fa5 Explicit valence for atom # 1 B, 5, is greater than permitted\n",
      "qmof-6f67857 Explicit valence for atom # 3 C, 5, is greater than permitted\n",
      "qmof-9cb1e2c Explicit valence for atom # 1 B, 5, is greater than permitted\n",
      "qmof-8ebe03b Explicit valence for atom # 5 C, 5, is greater than permitted\n",
      "qmof-6d61160 Explicit valence for atom # 3 C, 5, is greater than permitted\n",
      "qmof-c9e3c56 Explicit valence for atom # 3 C, 5, is greater than permitted\n",
      "qmof-76ed8fc Explicit valence for atom # 3 C, 5, is greater than permitted\n",
      "qmof-10741df Explicit valence for atom # 6 B, 5, is greater than permitted\n",
      "qmof-a952798 Explicit valence for atom # 6 B, 5, is greater than permitted\n",
      "qmof-c26f09c Explicit valence for atom # 7 B, 5, is greater than permitted\n",
      "qmof-4cbf5c8 Explicit valence for atom # 2 B, 5, is greater than permitted\n",
      "qmof-008a6ec Explicit valence for atom # 7 B, 5, is greater than permitted\n",
      "qmof-d513970 Explicit valence for atom # 7 B, 5, is greater than permitted\n",
      "qmof-721c324 Explicit valence for atom # 20 B, 5, is greater than permitted\n",
      "qmof-fa69f14 Explicit valence for atom # 9 B, 5, is greater than permitted\n",
      "qmof-968577c Explicit valence for atom # 1 B, 5, is greater than permitted\n",
      "qmof-52dc25d Explicit valence for atom # 11 B, 5, is greater than permitted\n",
      "qmof-0691242 Explicit valence for atom # 11 B, 5, is greater than permitted\n",
      "qmof-51966a1 Explicit valence for atom # 13 B, 5, is greater than permitted\n",
      "qmof-7f0ff56 Explicit valence for atom # 1 B, 5, is greater than permitted\n",
      "qmof-1106f49 Explicit valence for atom # 13 B, 5, is greater than permitted\n",
      "qmof-4a00ee0 Explicit valence for atom # 3 B, 5, is greater than permitted\n",
      "qmof-e7a1a72 Explicit valence for atom # 10 B, 5, is greater than permitted\n",
      "qmof-3f33bff Explicit valence for atom # 1 B, 5, is greater than permitted\n",
      "qmof-ae0f40c Explicit valence for atom # 1 B, 5, is greater than permitted\n",
      "qmof-5fe5f33 Explicit valence for atom # 17 C, 5, is greater than permitted\n",
      "qmof-347261d Explicit valence for atom # 1 B, 5, is greater than permitted\n",
      "qmof-538e5ff Explicit valence for atom # 14 B, 5, is greater than permitted\n",
      "qmof-cc6fd4d Explicit valence for atom # 4 B, 5, is greater than permitted\n",
      "qmof-ce0602b Explicit valence for atom # 4 B, 5, is greater than permitted\n",
      "qmof-ee77db8 Explicit valence for atom # 1 B, 5, is greater than permitted\n",
      "qmof-8ccaa8e Explicit valence for atom # 3 C, 5, is greater than permitted\n",
      "qmof-05dadc1 Explicit valence for atom # 3 B, 5, is greater than permitted\n",
      "qmof-658c0fd Explicit valence for atom # 2 B, 5, is greater than permitted\n",
      "qmof-a7e57bb Explicit valence for atom # 2 B, 5, is greater than permitted\n",
      "qmof-60db40b Explicit valence for atom # 2 B, 5, is greater than permitted\n",
      "qmof-79ae55e Explicit valence for atom # 2 B, 5, is greater than permitted\n",
      "qmof-d092156 Explicit valence for atom # 15 C, 5, is greater than permitted\n",
      "qmof-f2d2091 Explicit valence for atom # 4 B, 5, is greater than permitted\n",
      "qmof-a57e16b Explicit valence for atom # 1 B, 5, is greater than permitted\n",
      "qmof-d7c9623 Explicit valence for atom # 6 B, 5, is greater than permitted\n",
      "qmof-cd664ad Explicit valence for atom # 1 B, 5, is greater than permitted\n",
      "qmof-ab8259d Explicit valence for atom # 6 B, 5, is greater than permitted\n",
      "qmof-d76cb3a Explicit valence for atom # 4 B, 5, is greater than permitted\n",
      "qmof-e778e22 Explicit valence for atom # 2 B, 5, is greater than permitted\n",
      "qmof-74662f0 Explicit valence for atom # 3 B, 5, is greater than permitted\n",
      "qmof-e50605b Explicit valence for atom # 3 C, 5, is greater than permitted\n",
      "qmof-68f63a9 Explicit valence for atom # 1 B, 5, is greater than permitted\n",
      "qmof-a1c84c4 Explicit valence for atom # 6 B, 5, is greater than permitted\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "from pymatgen.core.structure import Structure\n",
    "\n",
    "from dgl.base import DGLError\n",
    "from rdkit.Chem.rdchem import AtomValenceException\n",
    "from rdkit import RDLogger\n",
    "from openbabel.pybel import ob\n",
    "\n",
    "from cgcgnet.featurizer import get_2cg_inputs\n",
    "\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "warnings.simplefilter(\"ignore\")\n",
    "RDLogger.DisableLog(\"rdApp.*\")\n",
    "ob.obErrorLog.SetOutputLevel(0)\n",
    "\n",
    "graphs, labels = [], []\n",
    "\n",
    "for q, s in zip(qmof, struct_data):\n",
    "    if \"hse06\" in q[\"outputs\"].keys():\n",
    "        structure = Structure.from_dict(s[\"structure\"])\n",
    "        try:\n",
    "            graph = get_2cg_inputs(structure)\n",
    "            graphs.append(graph)\n",
    "            labels.append([q[\"outputs\"][\"hse06\"][\"bandgap\"]])\n",
    "        except (KeyError, IndexError, DGLError, AtomValenceException) as err:\n",
    "            print(q[\"qmof_id\"], err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10718\n",
      "10718\n"
     ]
    }
   ],
   "source": [
    "print(len(graphs))\n",
    "print(len(labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Prepare PyTorch (DGL) data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$CG^2$-Net framework is implemented using [PyTorch](https://pytorch.org) and [Deep Graph Library (DGL)](https://www.dgl.ai) libraries. All data divided into training, validation, and test subsets are converted into [`torch.utils.data.DataLoader`](https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader) entities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader\n",
    "from cgcgnet.utils import get_stratified_folds, get_samples, collate_fn\n",
    "\n",
    "\n",
    "RANDOM_STATE = 0\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "graphs_train_valid, graphs_test, labels_train_valid, labels_test = train_test_split(\n",
    "    graphs,\n",
    "    labels,\n",
    "    test_size=1 / 10,\n",
    "    random_state=RANDOM_STATE,\n",
    "    stratify=get_stratified_folds(labels),\n",
    ")\n",
    "graphs_train, graphs_valid, labels_train, labels_valid = train_test_split(\n",
    "    graphs_train_valid,\n",
    "    labels_train_valid,\n",
    "    test_size=1 / 9,\n",
    "    random_state=RANDOM_STATE,\n",
    "    stratify=get_stratified_folds(labels_train_valid),\n",
    ")\n",
    "\n",
    "loader_train = DataLoader(\n",
    "    get_samples(graphs_train, labels_train),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    "    collate_fn=collate_fn,\n",
    ")\n",
    "loader_valid = DataLoader(\n",
    "    get_samples(graphs_valid, labels_valid),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    collate_fn=collate_fn,\n",
    ")\n",
    "loader_test = DataLoader(\n",
    "    get_samples(graphs_test, labels_test),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    collate_fn=collate_fn,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Initialize model, loss function, and optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In accordance with our experiments, the [GraphSAGE](https://doi.org/10.48550/arXiv.1706.02216) message-passing mechanism provides the highest overall perfomance in modeling properties of reticular materials. Therefore, here we initialize the `SAGEConvModel` in conjunction with [Adam](https://doi.org/10.48550/arXiv.1412.6980) optimizer; the mean squared error is used as a loss function. The `PATIENCE` parameter corresponds to early-stopping criterion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn import MSELoss\n",
    "from torch.optim import Adam\n",
    "\n",
    "from cgcgnet.nn import SAGEConvModel\n",
    "from cgcgnet.utils import EarlyStopping\n",
    "\n",
    "\n",
    "LEARNING_RATE = 1e-3\n",
    "PATIENCE = 50\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "model = SAGEConvModel().to(DEVICE)\n",
    "loss_fn = MSELoss()\n",
    "optimizer = Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "stopper = EarlyStopping(prefix=\"hse06_bandgap\", patience=PATIENCE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Train $CG^2$-Net model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can train the initialized model using simplistic training loop implemented in the `cgcgnet.nn` module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-----------------------------------\n",
      "train loss: 16.072250  [    0/ 8574]\n",
      "train loss: 0.635301  [ 3200/ 8574]\n",
      "train loss: 0.423649  [ 6400/ 8574]\n",
      "valid loss: 0.464042 \n",
      "\n",
      "Epoch 2\n",
      "-----------------------------------\n",
      "train loss: 0.644926  [    0/ 8574]\n",
      "train loss: 0.396809  [ 3200/ 8574]\n",
      "train loss: 0.639479  [ 6400/ 8574]\n",
      "valid loss: 0.354791 \n",
      "\n",
      "Epoch 3\n",
      "-----------------------------------\n",
      "train loss: 0.505838  [    0/ 8574]\n",
      "train loss: 0.402150  [ 3200/ 8574]\n",
      "train loss: 0.240160  [ 6400/ 8574]\n",
      "valid loss: 0.347572 \n",
      "\n",
      "Epoch 4\n",
      "-----------------------------------\n",
      "train loss: 0.255367  [    0/ 8574]\n",
      "train loss: 0.297830  [ 3200/ 8574]\n",
      "train loss: 0.213291  [ 6400/ 8574]\n",
      "valid loss: 0.312485 \n",
      "\n",
      "Epoch 5\n",
      "-----------------------------------\n",
      "train loss: 0.205765  [    0/ 8574]\n",
      "train loss: 0.178630  [ 3200/ 8574]\n",
      "train loss: 0.289767  [ 6400/ 8574]\n",
      "valid loss: 0.393052 \n",
      "\n",
      "Epoch 6\n",
      "-----------------------------------\n",
      "train loss: 0.319856  [    0/ 8574]\n",
      "train loss: 0.247658  [ 3200/ 8574]\n",
      "train loss: 0.382469  [ 6400/ 8574]\n",
      "valid loss: 0.286684 \n",
      "\n",
      "Epoch 7\n",
      "-----------------------------------\n",
      "train loss: 0.326475  [    0/ 8574]\n",
      "train loss: 0.489391  [ 3200/ 8574]\n",
      "train loss: 0.261775  [ 6400/ 8574]\n",
      "valid loss: 0.302842 \n",
      "\n",
      "Epoch 8\n",
      "-----------------------------------\n",
      "train loss: 0.131174  [    0/ 8574]\n",
      "train loss: 0.180763  [ 3200/ 8574]\n",
      "train loss: 0.151101  [ 6400/ 8574]\n",
      "valid loss: 0.277108 \n",
      "\n",
      "Epoch 9\n",
      "-----------------------------------\n",
      "train loss: 0.194291  [    0/ 8574]\n",
      "train loss: 0.139096  [ 3200/ 8574]\n",
      "train loss: 0.178655  [ 6400/ 8574]\n",
      "valid loss: 0.342817 \n",
      "\n",
      "Epoch 10\n",
      "-----------------------------------\n",
      "train loss: 0.381607  [    0/ 8574]\n",
      "train loss: 0.160010  [ 3200/ 8574]\n",
      "train loss: 0.250966  [ 6400/ 8574]\n",
      "valid loss: 0.281021 \n",
      "\n",
      "Epoch 11\n",
      "-----------------------------------\n",
      "train loss: 0.193350  [    0/ 8574]\n",
      "train loss: 0.293544  [ 3200/ 8574]\n",
      "train loss: 0.252811  [ 6400/ 8574]\n",
      "valid loss: 0.309466 \n",
      "\n",
      "Epoch 12\n",
      "-----------------------------------\n",
      "train loss: 0.169300  [    0/ 8574]\n",
      "train loss: 0.223379  [ 3200/ 8574]\n",
      "train loss: 0.173495  [ 6400/ 8574]\n",
      "valid loss: 0.297813 \n",
      "\n",
      "Epoch 13\n",
      "-----------------------------------\n",
      "train loss: 0.167623  [    0/ 8574]\n",
      "train loss: 0.177749  [ 3200/ 8574]\n",
      "train loss: 0.284818  [ 6400/ 8574]\n",
      "valid loss: 0.276401 \n",
      "\n",
      "Epoch 14\n",
      "-----------------------------------\n",
      "train loss: 0.344769  [    0/ 8574]\n",
      "train loss: 0.206043  [ 3200/ 8574]\n",
      "train loss: 0.263075  [ 6400/ 8574]\n",
      "valid loss: 0.285092 \n",
      "\n",
      "Epoch 15\n",
      "-----------------------------------\n",
      "train loss: 0.373805  [    0/ 8574]\n",
      "train loss: 0.214907  [ 3200/ 8574]\n",
      "train loss: 0.158823  [ 6400/ 8574]\n",
      "valid loss: 0.274334 \n",
      "\n",
      "Epoch 16\n",
      "-----------------------------------\n",
      "train loss: 0.254532  [    0/ 8574]\n",
      "train loss: 0.206471  [ 3200/ 8574]\n",
      "train loss: 0.290624  [ 6400/ 8574]\n",
      "valid loss: 0.256609 \n",
      "\n",
      "Epoch 17\n",
      "-----------------------------------\n",
      "train loss: 0.345296  [    0/ 8574]\n",
      "train loss: 0.647178  [ 3200/ 8574]\n",
      "train loss: 0.120050  [ 6400/ 8574]\n",
      "valid loss: 0.306658 \n",
      "\n",
      "Epoch 18\n",
      "-----------------------------------\n",
      "train loss: 0.142601  [    0/ 8574]\n",
      "train loss: 0.362349  [ 3200/ 8574]\n",
      "train loss: 0.203796  [ 6400/ 8574]\n",
      "valid loss: 0.322177 \n",
      "\n",
      "Epoch 19\n",
      "-----------------------------------\n",
      "train loss: 0.225405  [    0/ 8574]\n",
      "train loss: 0.218878  [ 3200/ 8574]\n",
      "train loss: 0.174493  [ 6400/ 8574]\n",
      "valid loss: 0.266505 \n",
      "\n",
      "Epoch 20\n",
      "-----------------------------------\n",
      "train loss: 0.377546  [    0/ 8574]\n",
      "train loss: 0.344327  [ 3200/ 8574]\n",
      "train loss: 0.249745  [ 6400/ 8574]\n",
      "valid loss: 0.254964 \n",
      "\n",
      "Epoch 21\n",
      "-----------------------------------\n",
      "train loss: 0.184316  [    0/ 8574]\n",
      "train loss: 0.138513  [ 3200/ 8574]\n",
      "train loss: 0.217085  [ 6400/ 8574]\n",
      "valid loss: 0.281475 \n",
      "\n",
      "Epoch 22\n",
      "-----------------------------------\n",
      "train loss: 0.160072  [    0/ 8574]\n",
      "train loss: 0.127309  [ 3200/ 8574]\n",
      "train loss: 0.261399  [ 6400/ 8574]\n",
      "valid loss: 0.271779 \n",
      "\n",
      "Epoch 23\n",
      "-----------------------------------\n",
      "train loss: 0.108894  [    0/ 8574]\n",
      "train loss: 0.136897  [ 3200/ 8574]\n",
      "train loss: 0.146350  [ 6400/ 8574]\n",
      "valid loss: 0.260188 \n",
      "\n",
      "Epoch 24\n",
      "-----------------------------------\n",
      "train loss: 0.139233  [    0/ 8574]\n",
      "train loss: 0.132681  [ 3200/ 8574]\n",
      "train loss: 0.077355  [ 6400/ 8574]\n",
      "valid loss: 0.244544 \n",
      "\n",
      "Epoch 25\n",
      "-----------------------------------\n",
      "train loss: 0.383081  [    0/ 8574]\n",
      "train loss: 0.132890  [ 3200/ 8574]\n",
      "train loss: 0.192480  [ 6400/ 8574]\n",
      "valid loss: 0.290520 \n",
      "\n",
      "Epoch 26\n",
      "-----------------------------------\n",
      "train loss: 0.132131  [    0/ 8574]\n",
      "train loss: 0.104899  [ 3200/ 8574]\n",
      "train loss: 0.165327  [ 6400/ 8574]\n",
      "valid loss: 0.321436 \n",
      "\n",
      "Epoch 27\n",
      "-----------------------------------\n",
      "train loss: 0.154668  [    0/ 8574]\n",
      "train loss: 0.114642  [ 3200/ 8574]\n",
      "train loss: 0.165606  [ 6400/ 8574]\n",
      "valid loss: 0.300954 \n",
      "\n",
      "Epoch 28\n",
      "-----------------------------------\n",
      "train loss: 0.117143  [    0/ 8574]\n",
      "train loss: 0.080464  [ 3200/ 8574]\n",
      "train loss: 0.226839  [ 6400/ 8574]\n",
      "valid loss: 0.246642 \n",
      "\n",
      "Epoch 29\n",
      "-----------------------------------\n",
      "train loss: 0.087089  [    0/ 8574]\n",
      "train loss: 0.099700  [ 3200/ 8574]\n",
      "train loss: 0.106298  [ 6400/ 8574]\n",
      "valid loss: 0.273260 \n",
      "\n",
      "Epoch 30\n",
      "-----------------------------------\n",
      "train loss: 0.080416  [    0/ 8574]\n",
      "train loss: 0.145995  [ 3200/ 8574]\n",
      "train loss: 0.106546  [ 6400/ 8574]\n",
      "valid loss: 0.293339 \n",
      "\n",
      "Epoch 31\n",
      "-----------------------------------\n",
      "train loss: 0.117025  [    0/ 8574]\n",
      "train loss: 0.064517  [ 3200/ 8574]\n",
      "train loss: 0.140955  [ 6400/ 8574]\n",
      "valid loss: 0.276265 \n",
      "\n",
      "Epoch 32\n",
      "-----------------------------------\n",
      "train loss: 0.277244  [    0/ 8574]\n",
      "train loss: 0.083218  [ 3200/ 8574]\n",
      "train loss: 0.094877  [ 6400/ 8574]\n",
      "valid loss: 0.275333 \n",
      "\n",
      "Epoch 33\n",
      "-----------------------------------\n",
      "train loss: 0.074775  [    0/ 8574]\n",
      "train loss: 0.112349  [ 3200/ 8574]\n",
      "train loss: 0.078919  [ 6400/ 8574]\n",
      "valid loss: 0.284193 \n",
      "\n",
      "Epoch 34\n",
      "-----------------------------------\n",
      "train loss: 0.089589  [    0/ 8574]\n",
      "train loss: 0.084151  [ 3200/ 8574]\n",
      "train loss: 0.071204  [ 6400/ 8574]\n",
      "valid loss: 0.273925 \n",
      "\n",
      "Epoch 35\n",
      "-----------------------------------\n",
      "train loss: 0.075821  [    0/ 8574]\n",
      "train loss: 0.070228  [ 3200/ 8574]\n",
      "train loss: 0.183902  [ 6400/ 8574]\n",
      "valid loss: 0.285197 \n",
      "\n",
      "Epoch 36\n",
      "-----------------------------------\n",
      "train loss: 0.086904  [    0/ 8574]\n",
      "train loss: 0.094649  [ 3200/ 8574]\n",
      "train loss: 0.126658  [ 6400/ 8574]\n",
      "valid loss: 0.293835 \n",
      "\n",
      "Epoch 37\n",
      "-----------------------------------\n",
      "train loss: 0.101663  [    0/ 8574]\n",
      "train loss: 0.118998  [ 3200/ 8574]\n",
      "train loss: 0.100808  [ 6400/ 8574]\n",
      "valid loss: 0.266395 \n",
      "\n",
      "Epoch 38\n",
      "-----------------------------------\n",
      "train loss: 0.045304  [    0/ 8574]\n",
      "train loss: 0.137749  [ 3200/ 8574]\n",
      "train loss: 0.097669  [ 6400/ 8574]\n",
      "valid loss: 0.276488 \n",
      "\n",
      "Epoch 39\n",
      "-----------------------------------\n",
      "train loss: 0.074624  [    0/ 8574]\n",
      "train loss: 0.064122  [ 3200/ 8574]\n",
      "train loss: 0.098647  [ 6400/ 8574]\n",
      "valid loss: 0.276495 \n",
      "\n",
      "Epoch 40\n",
      "-----------------------------------\n",
      "train loss: 0.219558  [    0/ 8574]\n",
      "train loss: 0.069928  [ 3200/ 8574]\n",
      "train loss: 0.094052  [ 6400/ 8574]\n",
      "valid loss: 0.269836 \n",
      "\n",
      "Epoch 41\n",
      "-----------------------------------\n",
      "train loss: 0.089451  [    0/ 8574]\n",
      "train loss: 0.119361  [ 3200/ 8574]\n",
      "train loss: 0.112830  [ 6400/ 8574]\n",
      "valid loss: 0.243160 \n",
      "\n",
      "Epoch 42\n",
      "-----------------------------------\n",
      "train loss: 0.081416  [    0/ 8574]\n",
      "train loss: 0.159465  [ 3200/ 8574]\n",
      "train loss: 0.066982  [ 6400/ 8574]\n",
      "valid loss: 0.279147 \n",
      "\n",
      "Epoch 43\n",
      "-----------------------------------\n",
      "train loss: 0.081389  [    0/ 8574]\n",
      "train loss: 0.100787  [ 3200/ 8574]\n",
      "train loss: 0.091329  [ 6400/ 8574]\n",
      "valid loss: 0.248752 \n",
      "\n",
      "Epoch 44\n",
      "-----------------------------------\n",
      "train loss: 0.145417  [    0/ 8574]\n",
      "train loss: 0.262470  [ 3200/ 8574]\n",
      "train loss: 0.059228  [ 6400/ 8574]\n",
      "valid loss: 0.267984 \n",
      "\n",
      "Epoch 45\n",
      "-----------------------------------\n",
      "train loss: 0.117585  [    0/ 8574]\n",
      "train loss: 0.118293  [ 3200/ 8574]\n",
      "train loss: 0.086123  [ 6400/ 8574]\n",
      "valid loss: 0.257705 \n",
      "\n",
      "Epoch 46\n",
      "-----------------------------------\n",
      "train loss: 0.210213  [    0/ 8574]\n",
      "train loss: 0.071249  [ 3200/ 8574]\n",
      "train loss: 0.061664  [ 6400/ 8574]\n",
      "valid loss: 0.267433 \n",
      "\n",
      "Epoch 47\n",
      "-----------------------------------\n",
      "train loss: 0.061743  [    0/ 8574]\n",
      "train loss: 0.052890  [ 3200/ 8574]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.076396  [ 6400/ 8574]\n",
      "valid loss: 0.256360 \n",
      "\n",
      "Epoch 48\n",
      "-----------------------------------\n",
      "train loss: 0.072696  [    0/ 8574]\n",
      "train loss: 0.061887  [ 3200/ 8574]\n",
      "train loss: 0.069241  [ 6400/ 8574]\n",
      "valid loss: 0.251148 \n",
      "\n",
      "Epoch 49\n",
      "-----------------------------------\n",
      "train loss: 0.086514  [    0/ 8574]\n",
      "train loss: 0.068835  [ 3200/ 8574]\n",
      "train loss: 0.092119  [ 6400/ 8574]\n",
      "valid loss: 0.266969 \n",
      "\n",
      "Epoch 50\n",
      "-----------------------------------\n",
      "train loss: 0.072967  [    0/ 8574]\n",
      "train loss: 0.076100  [ 3200/ 8574]\n",
      "train loss: 0.077357  [ 6400/ 8574]\n",
      "valid loss: 0.250441 \n",
      "\n",
      "Epoch 51\n",
      "-----------------------------------\n",
      "train loss: 0.085696  [    0/ 8574]\n",
      "train loss: 0.217398  [ 3200/ 8574]\n",
      "train loss: 0.091978  [ 6400/ 8574]\n",
      "valid loss: 0.266724 \n",
      "\n",
      "Epoch 52\n",
      "-----------------------------------\n",
      "train loss: 0.064540  [    0/ 8574]\n",
      "train loss: 0.058132  [ 3200/ 8574]\n",
      "train loss: 0.090952  [ 6400/ 8574]\n",
      "valid loss: 0.251058 \n",
      "\n",
      "Epoch 53\n",
      "-----------------------------------\n",
      "train loss: 0.038602  [    0/ 8574]\n",
      "train loss: 0.120398  [ 3200/ 8574]\n",
      "train loss: 0.077401  [ 6400/ 8574]\n",
      "valid loss: 0.245042 \n",
      "\n",
      "Epoch 54\n",
      "-----------------------------------\n",
      "train loss: 0.039757  [    0/ 8574]\n",
      "train loss: 0.075960  [ 3200/ 8574]\n",
      "train loss: 0.094047  [ 6400/ 8574]\n",
      "valid loss: 0.251534 \n",
      "\n",
      "Epoch 55\n",
      "-----------------------------------\n",
      "train loss: 0.183827  [    0/ 8574]\n",
      "train loss: 0.039921  [ 3200/ 8574]\n",
      "train loss: 0.075573  [ 6400/ 8574]\n",
      "valid loss: 0.247715 \n",
      "\n",
      "Epoch 56\n",
      "-----------------------------------\n",
      "train loss: 0.039055  [    0/ 8574]\n",
      "train loss: 0.072554  [ 3200/ 8574]\n",
      "train loss: 0.062314  [ 6400/ 8574]\n",
      "valid loss: 0.242798 \n",
      "\n",
      "Epoch 57\n",
      "-----------------------------------\n",
      "train loss: 0.042369  [    0/ 8574]\n",
      "train loss: 0.081818  [ 3200/ 8574]\n",
      "train loss: 0.054996  [ 6400/ 8574]\n",
      "valid loss: 0.259334 \n",
      "\n",
      "Epoch 58\n",
      "-----------------------------------\n",
      "train loss: 0.056218  [    0/ 8574]\n",
      "train loss: 0.098784  [ 3200/ 8574]\n",
      "train loss: 0.092389  [ 6400/ 8574]\n",
      "valid loss: 0.261270 \n",
      "\n",
      "Epoch 59\n",
      "-----------------------------------\n",
      "train loss: 0.072017  [    0/ 8574]\n",
      "train loss: 0.062313  [ 3200/ 8574]\n",
      "train loss: 0.066018  [ 6400/ 8574]\n",
      "valid loss: 0.238220 \n",
      "\n",
      "Epoch 60\n",
      "-----------------------------------\n",
      "train loss: 0.072675  [    0/ 8574]\n",
      "train loss: 0.111224  [ 3200/ 8574]\n",
      "train loss: 0.061909  [ 6400/ 8574]\n",
      "valid loss: 0.259702 \n",
      "\n",
      "Epoch 61\n",
      "-----------------------------------\n",
      "train loss: 0.052370  [    0/ 8574]\n",
      "train loss: 0.038631  [ 3200/ 8574]\n",
      "train loss: 0.055959  [ 6400/ 8574]\n",
      "valid loss: 0.246854 \n",
      "\n",
      "Epoch 62\n",
      "-----------------------------------\n",
      "train loss: 0.051047  [    0/ 8574]\n",
      "train loss: 0.072141  [ 3200/ 8574]\n",
      "train loss: 0.031000  [ 6400/ 8574]\n",
      "valid loss: 0.247413 \n",
      "\n",
      "Epoch 63\n",
      "-----------------------------------\n",
      "train loss: 0.046496  [    0/ 8574]\n",
      "train loss: 0.064566  [ 3200/ 8574]\n",
      "train loss: 0.053798  [ 6400/ 8574]\n",
      "valid loss: 0.242854 \n",
      "\n",
      "Epoch 64\n",
      "-----------------------------------\n",
      "train loss: 0.049381  [    0/ 8574]\n",
      "train loss: 0.044059  [ 3200/ 8574]\n",
      "train loss: 0.057379  [ 6400/ 8574]\n",
      "valid loss: 0.256368 \n",
      "\n",
      "Epoch 65\n",
      "-----------------------------------\n",
      "train loss: 0.043908  [    0/ 8574]\n",
      "train loss: 0.057812  [ 3200/ 8574]\n",
      "train loss: 0.076826  [ 6400/ 8574]\n",
      "valid loss: 0.242758 \n",
      "\n",
      "Epoch 66\n",
      "-----------------------------------\n",
      "train loss: 0.098667  [    0/ 8574]\n",
      "train loss: 0.045766  [ 3200/ 8574]\n",
      "train loss: 0.058596  [ 6400/ 8574]\n",
      "valid loss: 0.235750 \n",
      "\n",
      "Epoch 67\n",
      "-----------------------------------\n",
      "train loss: 0.049396  [    0/ 8574]\n",
      "train loss: 0.052990  [ 3200/ 8574]\n",
      "train loss: 0.056882  [ 6400/ 8574]\n",
      "valid loss: 0.245587 \n",
      "\n",
      "Epoch 68\n",
      "-----------------------------------\n",
      "train loss: 0.034386  [    0/ 8574]\n",
      "train loss: 0.048034  [ 3200/ 8574]\n",
      "train loss: 0.054218  [ 6400/ 8574]\n",
      "valid loss: 0.253635 \n",
      "\n",
      "Epoch 69\n",
      "-----------------------------------\n",
      "train loss: 0.064581  [    0/ 8574]\n",
      "train loss: 0.031558  [ 3200/ 8574]\n",
      "train loss: 0.075713  [ 6400/ 8574]\n",
      "valid loss: 0.246290 \n",
      "\n",
      "Epoch 70\n",
      "-----------------------------------\n",
      "train loss: 0.039714  [    0/ 8574]\n",
      "train loss: 0.113553  [ 3200/ 8574]\n",
      "train loss: 0.080488  [ 6400/ 8574]\n",
      "valid loss: 0.259161 \n",
      "\n",
      "Epoch 71\n",
      "-----------------------------------\n",
      "train loss: 0.195517  [    0/ 8574]\n",
      "train loss: 0.052160  [ 3200/ 8574]\n",
      "train loss: 0.051836  [ 6400/ 8574]\n",
      "valid loss: 0.247487 \n",
      "\n",
      "Epoch 72\n",
      "-----------------------------------\n",
      "train loss: 0.033402  [    0/ 8574]\n",
      "train loss: 0.180427  [ 3200/ 8574]\n",
      "train loss: 0.059579  [ 6400/ 8574]\n",
      "valid loss: 0.244886 \n",
      "\n",
      "Epoch 73\n",
      "-----------------------------------\n",
      "train loss: 0.049264  [    0/ 8574]\n",
      "train loss: 0.207920  [ 3200/ 8574]\n",
      "train loss: 0.051853  [ 6400/ 8574]\n",
      "valid loss: 0.258914 \n",
      "\n",
      "Epoch 74\n",
      "-----------------------------------\n",
      "train loss: 0.078667  [    0/ 8574]\n",
      "train loss: 0.070935  [ 3200/ 8574]\n",
      "train loss: 0.126014  [ 6400/ 8574]\n",
      "valid loss: 0.272553 \n",
      "\n",
      "Epoch 75\n",
      "-----------------------------------\n",
      "train loss: 0.065189  [    0/ 8574]\n",
      "train loss: 0.059141  [ 3200/ 8574]\n",
      "train loss: 0.120247  [ 6400/ 8574]\n",
      "valid loss: 0.255396 \n",
      "\n",
      "Epoch 76\n",
      "-----------------------------------\n",
      "train loss: 0.161892  [    0/ 8574]\n",
      "train loss: 0.027965  [ 3200/ 8574]\n",
      "train loss: 0.060221  [ 6400/ 8574]\n",
      "valid loss: 0.263170 \n",
      "\n",
      "Epoch 77\n",
      "-----------------------------------\n",
      "train loss: 0.050390  [    0/ 8574]\n",
      "train loss: 0.040896  [ 3200/ 8574]\n",
      "train loss: 0.042112  [ 6400/ 8574]\n",
      "valid loss: 0.248380 \n",
      "\n",
      "Epoch 78\n",
      "-----------------------------------\n",
      "train loss: 0.035503  [    0/ 8574]\n",
      "train loss: 0.022617  [ 3200/ 8574]\n",
      "train loss: 0.082587  [ 6400/ 8574]\n",
      "valid loss: 0.253186 \n",
      "\n",
      "Epoch 79\n",
      "-----------------------------------\n",
      "train loss: 0.034508  [    0/ 8574]\n",
      "train loss: 0.024078  [ 3200/ 8574]\n",
      "train loss: 0.054594  [ 6400/ 8574]\n",
      "valid loss: 0.245487 \n",
      "\n",
      "Epoch 80\n",
      "-----------------------------------\n",
      "train loss: 0.042786  [    0/ 8574]\n",
      "train loss: 0.055457  [ 3200/ 8574]\n",
      "train loss: 0.019097  [ 6400/ 8574]\n",
      "valid loss: 0.233232 \n",
      "\n",
      "Epoch 81\n",
      "-----------------------------------\n",
      "train loss: 0.019858  [    0/ 8574]\n",
      "train loss: 0.054945  [ 3200/ 8574]\n",
      "train loss: 0.026590  [ 6400/ 8574]\n",
      "valid loss: 0.240485 \n",
      "\n",
      "Epoch 82\n",
      "-----------------------------------\n",
      "train loss: 0.026580  [    0/ 8574]\n",
      "train loss: 0.122671  [ 3200/ 8574]\n",
      "train loss: 0.062859  [ 6400/ 8574]\n",
      "valid loss: 0.234209 \n",
      "\n",
      "Epoch 83\n",
      "-----------------------------------\n",
      "train loss: 0.026934  [    0/ 8574]\n",
      "train loss: 0.029438  [ 3200/ 8574]\n",
      "train loss: 0.037216  [ 6400/ 8574]\n",
      "valid loss: 0.258833 \n",
      "\n",
      "Epoch 84\n",
      "-----------------------------------\n",
      "train loss: 0.096154  [    0/ 8574]\n",
      "train loss: 0.033422  [ 3200/ 8574]\n",
      "train loss: 0.094848  [ 6400/ 8574]\n",
      "valid loss: 0.280846 \n",
      "\n",
      "Epoch 85\n",
      "-----------------------------------\n",
      "train loss: 0.059897  [    0/ 8574]\n",
      "train loss: 0.028155  [ 3200/ 8574]\n",
      "train loss: 0.056358  [ 6400/ 8574]\n",
      "valid loss: 0.245544 \n",
      "\n",
      "Epoch 86\n",
      "-----------------------------------\n",
      "train loss: 0.028902  [    0/ 8574]\n",
      "train loss: 0.030895  [ 3200/ 8574]\n",
      "train loss: 0.031989  [ 6400/ 8574]\n",
      "valid loss: 0.255909 \n",
      "\n",
      "Epoch 87\n",
      "-----------------------------------\n",
      "train loss: 0.033027  [    0/ 8574]\n",
      "train loss: 0.078993  [ 3200/ 8574]\n",
      "train loss: 0.030608  [ 6400/ 8574]\n",
      "valid loss: 0.246215 \n",
      "\n",
      "Epoch 88\n",
      "-----------------------------------\n",
      "train loss: 0.031234  [    0/ 8574]\n",
      "train loss: 0.025730  [ 3200/ 8574]\n",
      "train loss: 0.150713  [ 6400/ 8574]\n",
      "valid loss: 0.245940 \n",
      "\n",
      "Epoch 89\n",
      "-----------------------------------\n",
      "train loss: 0.057854  [    0/ 8574]\n",
      "train loss: 0.050671  [ 3200/ 8574]\n",
      "train loss: 0.030807  [ 6400/ 8574]\n",
      "valid loss: 0.242237 \n",
      "\n",
      "Epoch 90\n",
      "-----------------------------------\n",
      "train loss: 0.068260  [    0/ 8574]\n",
      "train loss: 0.025743  [ 3200/ 8574]\n",
      "train loss: 0.068305  [ 6400/ 8574]\n",
      "valid loss: 0.268632 \n",
      "\n",
      "Epoch 91\n",
      "-----------------------------------\n",
      "train loss: 0.035749  [    0/ 8574]\n",
      "train loss: 0.037131  [ 3200/ 8574]\n",
      "train loss: 0.027394  [ 6400/ 8574]\n",
      "valid loss: 0.238049 \n",
      "\n",
      "Epoch 92\n",
      "-----------------------------------\n",
      "train loss: 0.021045  [    0/ 8574]\n",
      "train loss: 0.040475  [ 3200/ 8574]\n",
      "train loss: 0.027104  [ 6400/ 8574]\n",
      "valid loss: 0.245652 \n",
      "\n",
      "Epoch 93\n",
      "-----------------------------------\n",
      "train loss: 0.027159  [    0/ 8574]\n",
      "train loss: 0.028482  [ 3200/ 8574]\n",
      "train loss: 0.030987  [ 6400/ 8574]\n",
      "valid loss: 0.242074 \n",
      "\n",
      "Epoch 94\n",
      "-----------------------------------\n",
      "train loss: 0.019812  [    0/ 8574]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.038183  [ 3200/ 8574]\n",
      "train loss: 0.033523  [ 6400/ 8574]\n",
      "valid loss: 0.256392 \n",
      "\n",
      "Epoch 95\n",
      "-----------------------------------\n",
      "train loss: 0.037934  [    0/ 8574]\n",
      "train loss: 0.044755  [ 3200/ 8574]\n",
      "train loss: 0.052380  [ 6400/ 8574]\n",
      "valid loss: 0.257126 \n",
      "\n",
      "Epoch 96\n",
      "-----------------------------------\n",
      "train loss: 0.029199  [    0/ 8574]\n",
      "train loss: 0.045754  [ 3200/ 8574]\n",
      "train loss: 0.049559  [ 6400/ 8574]\n",
      "valid loss: 0.243797 \n",
      "\n",
      "Epoch 97\n",
      "-----------------------------------\n",
      "train loss: 0.042068  [    0/ 8574]\n",
      "train loss: 0.085267  [ 3200/ 8574]\n",
      "train loss: 0.051294  [ 6400/ 8574]\n",
      "valid loss: 0.255613 \n",
      "\n",
      "Epoch 98\n",
      "-----------------------------------\n",
      "train loss: 0.045131  [    0/ 8574]\n",
      "train loss: 0.024014  [ 3200/ 8574]\n",
      "train loss: 0.036452  [ 6400/ 8574]\n",
      "valid loss: 0.254714 \n",
      "\n",
      "Epoch 99\n",
      "-----------------------------------\n",
      "train loss: 0.045264  [    0/ 8574]\n",
      "train loss: 0.029253  [ 3200/ 8574]\n",
      "train loss: 0.045132  [ 6400/ 8574]\n",
      "valid loss: 0.267090 \n",
      "\n",
      "Epoch 100\n",
      "-----------------------------------\n",
      "train loss: 0.019500  [    0/ 8574]\n",
      "train loss: 0.042079  [ 3200/ 8574]\n",
      "train loss: 0.165671  [ 6400/ 8574]\n",
      "valid loss: 0.255542 \n",
      "\n",
      "Epoch 101\n",
      "-----------------------------------\n",
      "train loss: 0.066821  [    0/ 8574]\n",
      "train loss: 0.023693  [ 3200/ 8574]\n",
      "train loss: 0.030203  [ 6400/ 8574]\n",
      "valid loss: 0.247515 \n",
      "\n",
      "Epoch 102\n",
      "-----------------------------------\n",
      "train loss: 0.020719  [    0/ 8574]\n",
      "train loss: 0.163550  [ 3200/ 8574]\n",
      "train loss: 0.024990  [ 6400/ 8574]\n",
      "valid loss: 0.238853 \n",
      "\n",
      "Epoch 103\n",
      "-----------------------------------\n",
      "train loss: 0.049928  [    0/ 8574]\n",
      "train loss: 0.013720  [ 3200/ 8574]\n",
      "train loss: 0.042996  [ 6400/ 8574]\n",
      "valid loss: 0.256208 \n",
      "\n",
      "Epoch 104\n",
      "-----------------------------------\n",
      "train loss: 0.047893  [    0/ 8574]\n",
      "train loss: 0.031712  [ 3200/ 8574]\n",
      "train loss: 0.050802  [ 6400/ 8574]\n",
      "valid loss: 0.252657 \n",
      "\n",
      "Epoch 105\n",
      "-----------------------------------\n",
      "train loss: 0.042893  [    0/ 8574]\n",
      "train loss: 0.065586  [ 3200/ 8574]\n",
      "train loss: 0.055259  [ 6400/ 8574]\n",
      "valid loss: 0.237190 \n",
      "\n",
      "Epoch 106\n",
      "-----------------------------------\n",
      "train loss: 0.030905  [    0/ 8574]\n",
      "train loss: 0.028271  [ 3200/ 8574]\n",
      "train loss: 0.038655  [ 6400/ 8574]\n",
      "valid loss: 0.251618 \n",
      "\n",
      "Epoch 107\n",
      "-----------------------------------\n",
      "train loss: 0.038555  [    0/ 8574]\n",
      "train loss: 0.054588  [ 3200/ 8574]\n",
      "train loss: 0.035096  [ 6400/ 8574]\n",
      "valid loss: 0.242992 \n",
      "\n",
      "Epoch 108\n",
      "-----------------------------------\n",
      "train loss: 0.027593  [    0/ 8574]\n",
      "train loss: 0.028626  [ 3200/ 8574]\n",
      "train loss: 0.023173  [ 6400/ 8574]\n",
      "valid loss: 0.241632 \n",
      "\n",
      "Epoch 109\n",
      "-----------------------------------\n",
      "train loss: 0.026356  [    0/ 8574]\n",
      "train loss: 0.026710  [ 3200/ 8574]\n",
      "train loss: 0.033382  [ 6400/ 8574]\n",
      "valid loss: 0.235800 \n",
      "\n",
      "Epoch 110\n",
      "-----------------------------------\n",
      "train loss: 0.016147  [    0/ 8574]\n",
      "train loss: 0.029370  [ 3200/ 8574]\n",
      "train loss: 0.047006  [ 6400/ 8574]\n",
      "valid loss: 0.255409 \n",
      "\n",
      "Epoch 111\n",
      "-----------------------------------\n",
      "train loss: 0.028721  [    0/ 8574]\n",
      "train loss: 0.044718  [ 3200/ 8574]\n",
      "train loss: 0.022384  [ 6400/ 8574]\n",
      "valid loss: 0.248471 \n",
      "\n",
      "Epoch 112\n",
      "-----------------------------------\n",
      "train loss: 0.032835  [    0/ 8574]\n",
      "train loss: 0.043398  [ 3200/ 8574]\n",
      "train loss: 0.053208  [ 6400/ 8574]\n",
      "valid loss: 0.236539 \n",
      "\n",
      "Epoch 113\n",
      "-----------------------------------\n",
      "train loss: 0.021386  [    0/ 8574]\n",
      "train loss: 0.030650  [ 3200/ 8574]\n",
      "train loss: 0.017332  [ 6400/ 8574]\n",
      "valid loss: 0.232174 \n",
      "\n",
      "Epoch 114\n",
      "-----------------------------------\n",
      "train loss: 0.028433  [    0/ 8574]\n",
      "train loss: 0.029385  [ 3200/ 8574]\n",
      "train loss: 0.026126  [ 6400/ 8574]\n",
      "valid loss: 0.270177 \n",
      "\n",
      "Epoch 115\n",
      "-----------------------------------\n",
      "train loss: 0.027490  [    0/ 8574]\n",
      "train loss: 0.026261  [ 3200/ 8574]\n",
      "train loss: 0.041081  [ 6400/ 8574]\n",
      "valid loss: 0.248777 \n",
      "\n",
      "Epoch 116\n",
      "-----------------------------------\n",
      "train loss: 0.022452  [    0/ 8574]\n",
      "train loss: 0.026215  [ 3200/ 8574]\n",
      "train loss: 0.026553  [ 6400/ 8574]\n",
      "valid loss: 0.241243 \n",
      "\n",
      "Epoch 117\n",
      "-----------------------------------\n",
      "train loss: 0.028593  [    0/ 8574]\n",
      "train loss: 0.026048  [ 3200/ 8574]\n",
      "train loss: 0.040855  [ 6400/ 8574]\n",
      "valid loss: 0.267288 \n",
      "\n",
      "Epoch 118\n",
      "-----------------------------------\n",
      "train loss: 0.134396  [    0/ 8574]\n",
      "train loss: 0.031252  [ 3200/ 8574]\n",
      "train loss: 0.034720  [ 6400/ 8574]\n",
      "valid loss: 0.244973 \n",
      "\n",
      "Epoch 119\n",
      "-----------------------------------\n",
      "train loss: 0.030812  [    0/ 8574]\n",
      "train loss: 0.028755  [ 3200/ 8574]\n",
      "train loss: 0.033949  [ 6400/ 8574]\n",
      "valid loss: 0.233905 \n",
      "\n",
      "Epoch 120\n",
      "-----------------------------------\n",
      "train loss: 0.011586  [    0/ 8574]\n",
      "train loss: 0.017230  [ 3200/ 8574]\n",
      "train loss: 0.110969  [ 6400/ 8574]\n",
      "valid loss: 0.255812 \n",
      "\n",
      "Epoch 121\n",
      "-----------------------------------\n",
      "train loss: 0.032861  [    0/ 8574]\n",
      "train loss: 0.097812  [ 3200/ 8574]\n",
      "train loss: 0.045637  [ 6400/ 8574]\n",
      "valid loss: 0.244765 \n",
      "\n",
      "Epoch 122\n",
      "-----------------------------------\n",
      "train loss: 0.044307  [    0/ 8574]\n",
      "train loss: 0.076865  [ 3200/ 8574]\n",
      "train loss: 0.112859  [ 6400/ 8574]\n",
      "valid loss: 0.304214 \n",
      "\n",
      "Epoch 123\n",
      "-----------------------------------\n",
      "train loss: 0.137720  [    0/ 8574]\n",
      "train loss: 0.175337  [ 3200/ 8574]\n",
      "train loss: 0.118080  [ 6400/ 8574]\n",
      "valid loss: 0.237117 \n",
      "\n",
      "Epoch 124\n",
      "-----------------------------------\n",
      "train loss: 0.022636  [    0/ 8574]\n",
      "train loss: 0.037019  [ 3200/ 8574]\n",
      "train loss: 0.033791  [ 6400/ 8574]\n",
      "valid loss: 0.241088 \n",
      "\n",
      "Epoch 125\n",
      "-----------------------------------\n",
      "train loss: 0.153482  [    0/ 8574]\n",
      "train loss: 0.037253  [ 3200/ 8574]\n",
      "train loss: 0.028583  [ 6400/ 8574]\n",
      "valid loss: 0.237961 \n",
      "\n",
      "Epoch 126\n",
      "-----------------------------------\n",
      "train loss: 0.018209  [    0/ 8574]\n",
      "train loss: 0.015384  [ 3200/ 8574]\n",
      "train loss: 0.022867  [ 6400/ 8574]\n",
      "valid loss: 0.242187 \n",
      "\n",
      "Epoch 127\n",
      "-----------------------------------\n",
      "train loss: 0.017804  [    0/ 8574]\n",
      "train loss: 0.026100  [ 3200/ 8574]\n",
      "train loss: 0.015374  [ 6400/ 8574]\n",
      "valid loss: 0.234519 \n",
      "\n",
      "Epoch 128\n",
      "-----------------------------------\n",
      "train loss: 0.037677  [    0/ 8574]\n",
      "train loss: 0.014890  [ 3200/ 8574]\n",
      "train loss: 0.036375  [ 6400/ 8574]\n",
      "valid loss: 0.242031 \n",
      "\n",
      "Epoch 129\n",
      "-----------------------------------\n",
      "train loss: 0.023783  [    0/ 8574]\n",
      "train loss: 0.030011  [ 3200/ 8574]\n",
      "train loss: 0.015549  [ 6400/ 8574]\n",
      "valid loss: 0.237277 \n",
      "\n",
      "Epoch 130\n",
      "-----------------------------------\n",
      "train loss: 0.032191  [    0/ 8574]\n",
      "train loss: 0.012663  [ 3200/ 8574]\n",
      "train loss: 0.032296  [ 6400/ 8574]\n",
      "valid loss: 0.241416 \n",
      "\n",
      "Epoch 131\n",
      "-----------------------------------\n",
      "train loss: 0.021010  [    0/ 8574]\n",
      "train loss: 0.008492  [ 3200/ 8574]\n",
      "train loss: 0.019815  [ 6400/ 8574]\n",
      "valid loss: 0.255739 \n",
      "\n",
      "Epoch 132\n",
      "-----------------------------------\n",
      "train loss: 0.029893  [    0/ 8574]\n",
      "train loss: 0.018039  [ 3200/ 8574]\n",
      "train loss: 0.029087  [ 6400/ 8574]\n",
      "valid loss: 0.237607 \n",
      "\n",
      "Epoch 133\n",
      "-----------------------------------\n",
      "train loss: 0.014011  [    0/ 8574]\n",
      "train loss: 0.020767  [ 3200/ 8574]\n",
      "train loss: 0.019479  [ 6400/ 8574]\n",
      "valid loss: 0.241594 \n",
      "\n",
      "Epoch 134\n",
      "-----------------------------------\n",
      "train loss: 0.035836  [    0/ 8574]\n",
      "train loss: 0.033029  [ 3200/ 8574]\n",
      "train loss: 0.033265  [ 6400/ 8574]\n",
      "valid loss: 0.240866 \n",
      "\n",
      "Epoch 135\n",
      "-----------------------------------\n",
      "train loss: 0.014233  [    0/ 8574]\n",
      "train loss: 0.035889  [ 3200/ 8574]\n",
      "train loss: 0.028638  [ 6400/ 8574]\n",
      "valid loss: 0.252320 \n",
      "\n",
      "Epoch 136\n",
      "-----------------------------------\n",
      "train loss: 0.015260  [    0/ 8574]\n",
      "train loss: 0.014717  [ 3200/ 8574]\n",
      "train loss: 0.025231  [ 6400/ 8574]\n",
      "valid loss: 0.245420 \n",
      "\n",
      "Epoch 137\n",
      "-----------------------------------\n",
      "train loss: 0.030675  [    0/ 8574]\n",
      "train loss: 0.015203  [ 3200/ 8574]\n",
      "train loss: 0.033398  [ 6400/ 8574]\n",
      "valid loss: 0.240883 \n",
      "\n",
      "Epoch 138\n",
      "-----------------------------------\n",
      "train loss: 0.033469  [    0/ 8574]\n",
      "train loss: 0.023675  [ 3200/ 8574]\n",
      "train loss: 0.139984  [ 6400/ 8574]\n",
      "valid loss: 0.232745 \n",
      "\n",
      "Epoch 139\n",
      "-----------------------------------\n",
      "train loss: 0.023044  [    0/ 8574]\n",
      "train loss: 0.018734  [ 3200/ 8574]\n",
      "train loss: 0.024661  [ 6400/ 8574]\n",
      "valid loss: 0.236423 \n",
      "\n",
      "Epoch 140\n",
      "-----------------------------------\n",
      "train loss: 0.011170  [    0/ 8574]\n",
      "train loss: 0.025731  [ 3200/ 8574]\n",
      "train loss: 0.055429  [ 6400/ 8574]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid loss: 0.241913 \n",
      "\n",
      "Epoch 141\n",
      "-----------------------------------\n",
      "train loss: 0.035809  [    0/ 8574]\n",
      "train loss: 0.050801  [ 3200/ 8574]\n",
      "train loss: 0.031374  [ 6400/ 8574]\n",
      "valid loss: 0.245128 \n",
      "\n",
      "Epoch 142\n",
      "-----------------------------------\n",
      "train loss: 0.022550  [    0/ 8574]\n",
      "train loss: 0.030647  [ 3200/ 8574]\n",
      "train loss: 0.047714  [ 6400/ 8574]\n",
      "valid loss: 0.243721 \n",
      "\n",
      "Epoch 143\n",
      "-----------------------------------\n",
      "train loss: 0.027198  [    0/ 8574]\n",
      "train loss: 0.038449  [ 3200/ 8574]\n",
      "train loss: 0.062847  [ 6400/ 8574]\n",
      "valid loss: 0.261791 \n",
      "\n",
      "Epoch 144\n",
      "-----------------------------------\n",
      "train loss: 0.026232  [    0/ 8574]\n",
      "train loss: 0.022608  [ 3200/ 8574]\n",
      "train loss: 0.030399  [ 6400/ 8574]\n",
      "valid loss: 0.275967 \n",
      "\n",
      "Epoch 145\n",
      "-----------------------------------\n",
      "train loss: 0.060128  [    0/ 8574]\n",
      "train loss: 0.023810  [ 3200/ 8574]\n",
      "train loss: 0.051245  [ 6400/ 8574]\n",
      "valid loss: 0.256156 \n",
      "\n",
      "Epoch 146\n",
      "-----------------------------------\n",
      "train loss: 0.030541  [    0/ 8574]\n",
      "train loss: 0.036229  [ 3200/ 8574]\n",
      "train loss: 0.064197  [ 6400/ 8574]\n",
      "valid loss: 0.239588 \n",
      "\n",
      "Epoch 147\n",
      "-----------------------------------\n",
      "train loss: 0.022409  [    0/ 8574]\n",
      "train loss: 0.059314  [ 3200/ 8574]\n",
      "train loss: 0.019863  [ 6400/ 8574]\n",
      "valid loss: 0.239461 \n",
      "\n",
      "Epoch 148\n",
      "-----------------------------------\n",
      "train loss: 0.020580  [    0/ 8574]\n",
      "train loss: 0.028865  [ 3200/ 8574]\n",
      "train loss: 0.019801  [ 6400/ 8574]\n",
      "valid loss: 0.241576 \n",
      "\n",
      "Epoch 149\n",
      "-----------------------------------\n",
      "train loss: 0.016540  [    0/ 8574]\n",
      "train loss: 0.013985  [ 3200/ 8574]\n",
      "train loss: 0.021016  [ 6400/ 8574]\n",
      "valid loss: 0.235365 \n",
      "\n",
      "Epoch 150\n",
      "-----------------------------------\n",
      "train loss: 0.012400  [    0/ 8574]\n",
      "train loss: 0.019537  [ 3200/ 8574]\n",
      "train loss: 0.022264  [ 6400/ 8574]\n",
      "valid loss: 0.242678 \n",
      "\n",
      "Epoch 151\n",
      "-----------------------------------\n",
      "train loss: 0.017362  [    0/ 8574]\n",
      "train loss: 0.028641  [ 3200/ 8574]\n",
      "train loss: 0.020703  [ 6400/ 8574]\n",
      "valid loss: 0.244671 \n",
      "\n",
      "Epoch 152\n",
      "-----------------------------------\n",
      "train loss: 0.025868  [    0/ 8574]\n",
      "train loss: 0.036431  [ 3200/ 8574]\n",
      "train loss: 0.037307  [ 6400/ 8574]\n",
      "valid loss: 0.256152 \n",
      "\n",
      "Epoch 153\n",
      "-----------------------------------\n",
      "train loss: 0.024879  [    0/ 8574]\n",
      "train loss: 0.036541  [ 3200/ 8574]\n",
      "train loss: 0.033846  [ 6400/ 8574]\n",
      "valid loss: 0.238837 \n",
      "\n",
      "Epoch 154\n",
      "-----------------------------------\n",
      "train loss: 0.033529  [    0/ 8574]\n",
      "train loss: 0.028351  [ 3200/ 8574]\n",
      "train loss: 0.042080  [ 6400/ 8574]\n",
      "valid loss: 0.239595 \n",
      "\n",
      "Epoch 155\n",
      "-----------------------------------\n",
      "train loss: 0.022649  [    0/ 8574]\n",
      "train loss: 0.035692  [ 3200/ 8574]\n",
      "train loss: 0.030342  [ 6400/ 8574]\n",
      "valid loss: 0.238397 \n",
      "\n",
      "Epoch 156\n",
      "-----------------------------------\n",
      "train loss: 0.023992  [    0/ 8574]\n",
      "train loss: 0.033556  [ 3200/ 8574]\n",
      "train loss: 0.018511  [ 6400/ 8574]\n",
      "valid loss: 0.239245 \n",
      "\n",
      "Epoch 157\n",
      "-----------------------------------\n",
      "train loss: 0.020063  [    0/ 8574]\n",
      "train loss: 0.063270  [ 3200/ 8574]\n",
      "train loss: 0.026994  [ 6400/ 8574]\n",
      "valid loss: 0.248744 \n",
      "\n",
      "Epoch 158\n",
      "-----------------------------------\n",
      "train loss: 0.038997  [    0/ 8574]\n",
      "train loss: 0.133204  [ 3200/ 8574]\n",
      "train loss: 0.083526  [ 6400/ 8574]\n",
      "valid loss: 0.269071 \n",
      "\n",
      "Epoch 159\n",
      "-----------------------------------\n",
      "train loss: 0.057842  [    0/ 8574]\n",
      "train loss: 0.036442  [ 3200/ 8574]\n",
      "train loss: 0.027616  [ 6400/ 8574]\n",
      "valid loss: 0.238172 \n",
      "\n",
      "Epoch 160\n",
      "-----------------------------------\n",
      "train loss: 0.041873  [    0/ 8574]\n",
      "train loss: 0.016236  [ 3200/ 8574]\n",
      "train loss: 0.024367  [ 6400/ 8574]\n",
      "valid loss: 0.240943 \n",
      "\n",
      "Epoch 161\n",
      "-----------------------------------\n",
      "train loss: 0.013352  [    0/ 8574]\n",
      "train loss: 0.030913  [ 3200/ 8574]\n",
      "train loss: 0.025392  [ 6400/ 8574]\n",
      "valid loss: 0.232304 \n",
      "\n",
      "Epoch 162\n",
      "-----------------------------------\n",
      "train loss: 0.008488  [    0/ 8574]\n",
      "train loss: 0.008559  [ 3200/ 8574]\n",
      "train loss: 0.022113  [ 6400/ 8574]\n",
      "valid loss: 0.239121 \n",
      "\n",
      "Epoch 163\n",
      "-----------------------------------\n",
      "train loss: 0.015152  [    0/ 8574]\n",
      "train loss: 0.050474  [ 3200/ 8574]\n",
      "train loss: 0.011928  [ 6400/ 8574]\n",
      "valid loss: 0.231860 \n",
      "\n",
      "Epoch 164\n",
      "-----------------------------------\n",
      "train loss: 0.019099  [    0/ 8574]\n",
      "train loss: 0.011264  [ 3200/ 8574]\n",
      "train loss: 0.023897  [ 6400/ 8574]\n",
      "valid loss: 0.227190 \n",
      "\n",
      "Epoch 165\n",
      "-----------------------------------\n",
      "train loss: 0.014423  [    0/ 8574]\n",
      "train loss: 0.009945  [ 3200/ 8574]\n",
      "train loss: 0.015400  [ 6400/ 8574]\n",
      "valid loss: 0.237645 \n",
      "\n",
      "Epoch 166\n",
      "-----------------------------------\n",
      "train loss: 0.025361  [    0/ 8574]\n",
      "train loss: 0.009961  [ 3200/ 8574]\n",
      "train loss: 0.013080  [ 6400/ 8574]\n",
      "valid loss: 0.234911 \n",
      "\n",
      "Epoch 167\n",
      "-----------------------------------\n",
      "train loss: 0.017630  [    0/ 8574]\n",
      "train loss: 0.016424  [ 3200/ 8574]\n",
      "train loss: 0.015576  [ 6400/ 8574]\n",
      "valid loss: 0.237141 \n",
      "\n",
      "Epoch 168\n",
      "-----------------------------------\n",
      "train loss: 0.008269  [    0/ 8574]\n",
      "train loss: 0.010260  [ 3200/ 8574]\n",
      "train loss: 0.018310  [ 6400/ 8574]\n",
      "valid loss: 0.239406 \n",
      "\n",
      "Epoch 169\n",
      "-----------------------------------\n",
      "train loss: 0.018720  [    0/ 8574]\n",
      "train loss: 0.009666  [ 3200/ 8574]\n",
      "train loss: 0.014821  [ 6400/ 8574]\n",
      "valid loss: 0.235270 \n",
      "\n",
      "Epoch 170\n",
      "-----------------------------------\n",
      "train loss: 0.018049  [    0/ 8574]\n",
      "train loss: 0.018520  [ 3200/ 8574]\n",
      "train loss: 0.014638  [ 6400/ 8574]\n",
      "valid loss: 0.232757 \n",
      "\n",
      "Epoch 171\n",
      "-----------------------------------\n",
      "train loss: 0.016016  [    0/ 8574]\n",
      "train loss: 0.024547  [ 3200/ 8574]\n",
      "train loss: 0.027490  [ 6400/ 8574]\n",
      "valid loss: 0.243183 \n",
      "\n",
      "Epoch 172\n",
      "-----------------------------------\n",
      "train loss: 0.028091  [    0/ 8574]\n",
      "train loss: 0.026014  [ 3200/ 8574]\n",
      "train loss: 0.016624  [ 6400/ 8574]\n",
      "valid loss: 0.226584 \n",
      "\n",
      "Epoch 173\n",
      "-----------------------------------\n",
      "train loss: 0.023667  [    0/ 8574]\n",
      "train loss: 0.018024  [ 3200/ 8574]\n",
      "train loss: 0.020340  [ 6400/ 8574]\n",
      "valid loss: 0.240673 \n",
      "\n",
      "Epoch 174\n",
      "-----------------------------------\n",
      "train loss: 0.044589  [    0/ 8574]\n",
      "train loss: 0.026299  [ 3200/ 8574]\n",
      "train loss: 0.025994  [ 6400/ 8574]\n",
      "valid loss: 0.231289 \n",
      "\n",
      "Epoch 175\n",
      "-----------------------------------\n",
      "train loss: 0.009831  [    0/ 8574]\n",
      "train loss: 0.030177  [ 3200/ 8574]\n",
      "train loss: 0.012314  [ 6400/ 8574]\n",
      "valid loss: 0.240950 \n",
      "\n",
      "Epoch 176\n",
      "-----------------------------------\n",
      "train loss: 0.025768  [    0/ 8574]\n",
      "train loss: 0.025452  [ 3200/ 8574]\n",
      "train loss: 0.015053  [ 6400/ 8574]\n",
      "valid loss: 0.241354 \n",
      "\n",
      "Epoch 177\n",
      "-----------------------------------\n",
      "train loss: 0.022877  [    0/ 8574]\n",
      "train loss: 0.044505  [ 3200/ 8574]\n",
      "train loss: 0.044745  [ 6400/ 8574]\n",
      "valid loss: 0.266920 \n",
      "\n",
      "Epoch 178\n",
      "-----------------------------------\n",
      "train loss: 0.040540  [    0/ 8574]\n",
      "train loss: 0.052833  [ 3200/ 8574]\n",
      "train loss: 0.062076  [ 6400/ 8574]\n",
      "valid loss: 0.250656 \n",
      "\n",
      "Epoch 179\n",
      "-----------------------------------\n",
      "train loss: 0.036570  [    0/ 8574]\n",
      "train loss: 0.029606  [ 3200/ 8574]\n",
      "train loss: 0.030279  [ 6400/ 8574]\n",
      "valid loss: 0.235813 \n",
      "\n",
      "Epoch 180\n",
      "-----------------------------------\n",
      "train loss: 0.029702  [    0/ 8574]\n",
      "train loss: 0.029354  [ 3200/ 8574]\n",
      "train loss: 0.022094  [ 6400/ 8574]\n",
      "valid loss: 0.233729 \n",
      "\n",
      "Epoch 181\n",
      "-----------------------------------\n",
      "train loss: 0.056736  [    0/ 8574]\n",
      "train loss: 0.040714  [ 3200/ 8574]\n",
      "train loss: 0.014260  [ 6400/ 8574]\n",
      "valid loss: 0.234561 \n",
      "\n",
      "Epoch 182\n",
      "-----------------------------------\n",
      "train loss: 0.013183  [    0/ 8574]\n",
      "train loss: 0.010819  [ 3200/ 8574]\n",
      "train loss: 0.010720  [ 6400/ 8574]\n",
      "valid loss: 0.226933 \n",
      "\n",
      "Epoch 183\n",
      "-----------------------------------\n",
      "train loss: 0.020082  [    0/ 8574]\n",
      "train loss: 0.014898  [ 3200/ 8574]\n",
      "train loss: 0.035659  [ 6400/ 8574]\n",
      "valid loss: 0.229576 \n",
      "\n",
      "Epoch 184\n",
      "-----------------------------------\n",
      "train loss: 0.015768  [    0/ 8574]\n",
      "train loss: 0.009627  [ 3200/ 8574]\n",
      "train loss: 0.016478  [ 6400/ 8574]\n",
      "valid loss: 0.227876 \n",
      "\n",
      "Epoch 185\n",
      "-----------------------------------\n",
      "train loss: 0.015871  [    0/ 8574]\n",
      "train loss: 0.007392  [ 3200/ 8574]\n",
      "train loss: 0.006011  [ 6400/ 8574]\n",
      "valid loss: 0.230675 \n",
      "\n",
      "Epoch 186\n",
      "-----------------------------------\n",
      "train loss: 0.015366  [    0/ 8574]\n",
      "train loss: 0.012166  [ 3200/ 8574]\n",
      "train loss: 0.017244  [ 6400/ 8574]\n",
      "valid loss: 0.232222 \n",
      "\n",
      "Epoch 187\n",
      "-----------------------------------\n",
      "train loss: 0.011467  [    0/ 8574]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.014797  [ 3200/ 8574]\n",
      "train loss: 0.012571  [ 6400/ 8574]\n",
      "valid loss: 0.231345 \n",
      "\n",
      "Epoch 188\n",
      "-----------------------------------\n",
      "train loss: 0.023480  [    0/ 8574]\n",
      "train loss: 0.010429  [ 3200/ 8574]\n",
      "train loss: 0.011290  [ 6400/ 8574]\n",
      "valid loss: 0.230270 \n",
      "\n",
      "Epoch 189\n",
      "-----------------------------------\n",
      "train loss: 0.020286  [    0/ 8574]\n",
      "train loss: 0.029197  [ 3200/ 8574]\n",
      "train loss: 0.017984  [ 6400/ 8574]\n",
      "valid loss: 0.234305 \n",
      "\n",
      "Epoch 190\n",
      "-----------------------------------\n",
      "train loss: 0.037351  [    0/ 8574]\n",
      "train loss: 0.021629  [ 3200/ 8574]\n",
      "train loss: 0.050746  [ 6400/ 8574]\n",
      "valid loss: 0.237284 \n",
      "\n",
      "Epoch 191\n",
      "-----------------------------------\n",
      "train loss: 0.011157  [    0/ 8574]\n",
      "train loss: 0.017407  [ 3200/ 8574]\n",
      "train loss: 0.025311  [ 6400/ 8574]\n",
      "valid loss: 0.243405 \n",
      "\n",
      "Epoch 192\n",
      "-----------------------------------\n",
      "train loss: 0.022489  [    0/ 8574]\n",
      "train loss: 0.026705  [ 3200/ 8574]\n",
      "train loss: 0.014640  [ 6400/ 8574]\n",
      "valid loss: 0.236236 \n",
      "\n",
      "Epoch 193\n",
      "-----------------------------------\n",
      "train loss: 0.021978  [    0/ 8574]\n",
      "train loss: 0.010894  [ 3200/ 8574]\n",
      "train loss: 0.153697  [ 6400/ 8574]\n",
      "valid loss: 0.273274 \n",
      "\n",
      "Epoch 194\n",
      "-----------------------------------\n",
      "train loss: 0.076070  [    0/ 8574]\n",
      "train loss: 0.019673  [ 3200/ 8574]\n",
      "train loss: 0.020305  [ 6400/ 8574]\n",
      "valid loss: 0.255043 \n",
      "\n",
      "Epoch 195\n",
      "-----------------------------------\n",
      "train loss: 0.039483  [    0/ 8574]\n",
      "train loss: 0.051230  [ 3200/ 8574]\n",
      "train loss: 0.032854  [ 6400/ 8574]\n",
      "valid loss: 0.262933 \n",
      "\n",
      "Epoch 196\n",
      "-----------------------------------\n",
      "train loss: 0.046526  [    0/ 8574]\n",
      "train loss: 0.055630  [ 3200/ 8574]\n",
      "train loss: 0.030787  [ 6400/ 8574]\n",
      "valid loss: 0.247830 \n",
      "\n",
      "Epoch 197\n",
      "-----------------------------------\n",
      "train loss: 0.025888  [    0/ 8574]\n",
      "train loss: 0.017060  [ 3200/ 8574]\n",
      "train loss: 0.033340  [ 6400/ 8574]\n",
      "valid loss: 0.236505 \n",
      "\n",
      "Epoch 198\n",
      "-----------------------------------\n",
      "train loss: 0.020233  [    0/ 8574]\n",
      "train loss: 0.016237  [ 3200/ 8574]\n",
      "train loss: 0.130513  [ 6400/ 8574]\n",
      "valid loss: 0.231936 \n",
      "\n",
      "Epoch 199\n",
      "-----------------------------------\n",
      "train loss: 0.016583  [    0/ 8574]\n",
      "train loss: 0.008224  [ 3200/ 8574]\n",
      "train loss: 0.107282  [ 6400/ 8574]\n",
      "valid loss: 0.240613 \n",
      "\n",
      "Epoch 200\n",
      "-----------------------------------\n",
      "train loss: 0.009807  [    0/ 8574]\n",
      "train loss: 0.020575  [ 3200/ 8574]\n",
      "train loss: 0.016432  [ 6400/ 8574]\n",
      "valid loss: 0.231165 \n",
      "\n",
      "Epoch 201\n",
      "-----------------------------------\n",
      "train loss: 0.016715  [    0/ 8574]\n",
      "train loss: 0.022614  [ 3200/ 8574]\n",
      "train loss: 0.012574  [ 6400/ 8574]\n",
      "valid loss: 0.231645 \n",
      "\n",
      "Epoch 202\n",
      "-----------------------------------\n",
      "train loss: 0.012311  [    0/ 8574]\n",
      "train loss: 0.008572  [ 3200/ 8574]\n",
      "train loss: 0.011916  [ 6400/ 8574]\n",
      "valid loss: 0.231331 \n",
      "\n",
      "Epoch 203\n",
      "-----------------------------------\n",
      "train loss: 0.010483  [    0/ 8574]\n",
      "train loss: 0.070446  [ 3200/ 8574]\n",
      "train loss: 0.019650  [ 6400/ 8574]\n",
      "valid loss: 0.230825 \n",
      "\n",
      "Epoch 204\n",
      "-----------------------------------\n",
      "train loss: 0.007768  [    0/ 8574]\n",
      "train loss: 0.014300  [ 3200/ 8574]\n",
      "train loss: 0.017818  [ 6400/ 8574]\n",
      "valid loss: 0.238960 \n",
      "\n",
      "Epoch 205\n",
      "-----------------------------------\n",
      "train loss: 0.010354  [    0/ 8574]\n",
      "train loss: 0.017184  [ 3200/ 8574]\n",
      "train loss: 0.016109  [ 6400/ 8574]\n",
      "valid loss: 0.239636 \n",
      "\n",
      "Epoch 206\n",
      "-----------------------------------\n",
      "train loss: 0.017916  [    0/ 8574]\n",
      "train loss: 0.010762  [ 3200/ 8574]\n",
      "train loss: 0.009259  [ 6400/ 8574]\n",
      "valid loss: 0.240175 \n",
      "\n",
      "Epoch 207\n",
      "-----------------------------------\n",
      "train loss: 0.008685  [    0/ 8574]\n",
      "train loss: 0.013514  [ 3200/ 8574]\n",
      "train loss: 0.091624  [ 6400/ 8574]\n",
      "valid loss: 0.235458 \n",
      "\n",
      "Epoch 208\n",
      "-----------------------------------\n",
      "train loss: 0.014716  [    0/ 8574]\n",
      "train loss: 0.111750  [ 3200/ 8574]\n",
      "train loss: 0.010541  [ 6400/ 8574]\n",
      "valid loss: 0.237437 \n",
      "\n",
      "Epoch 209\n",
      "-----------------------------------\n",
      "train loss: 0.016816  [    0/ 8574]\n",
      "train loss: 0.010342  [ 3200/ 8574]\n",
      "train loss: 0.017191  [ 6400/ 8574]\n",
      "valid loss: 0.233619 \n",
      "\n",
      "Epoch 210\n",
      "-----------------------------------\n",
      "train loss: 0.010462  [    0/ 8574]\n",
      "train loss: 0.009284  [ 3200/ 8574]\n",
      "train loss: 0.012388  [ 6400/ 8574]\n",
      "valid loss: 0.238379 \n",
      "\n",
      "Epoch 211\n",
      "-----------------------------------\n",
      "train loss: 0.012483  [    0/ 8574]\n",
      "train loss: 0.007387  [ 3200/ 8574]\n",
      "train loss: 0.058990  [ 6400/ 8574]\n",
      "valid loss: 0.242203 \n",
      "\n",
      "Epoch 212\n",
      "-----------------------------------\n",
      "train loss: 0.026021  [    0/ 8574]\n",
      "train loss: 0.007643  [ 3200/ 8574]\n",
      "train loss: 0.017470  [ 6400/ 8574]\n",
      "valid loss: 0.241759 \n",
      "\n",
      "Epoch 213\n",
      "-----------------------------------\n",
      "train loss: 0.020723  [    0/ 8574]\n",
      "train loss: 0.010540  [ 3200/ 8574]\n",
      "train loss: 0.018189  [ 6400/ 8574]\n",
      "valid loss: 0.233482 \n",
      "\n",
      "Epoch 214\n",
      "-----------------------------------\n",
      "train loss: 0.014195  [    0/ 8574]\n",
      "train loss: 0.021465  [ 3200/ 8574]\n",
      "train loss: 0.013407  [ 6400/ 8574]\n",
      "valid loss: 0.249997 \n",
      "\n",
      "Epoch 215\n",
      "-----------------------------------\n",
      "train loss: 0.021549  [    0/ 8574]\n",
      "train loss: 0.044632  [ 3200/ 8574]\n",
      "train loss: 0.018352  [ 6400/ 8574]\n",
      "valid loss: 0.230179 \n",
      "\n",
      "Epoch 216\n",
      "-----------------------------------\n",
      "train loss: 0.023640  [    0/ 8574]\n",
      "train loss: 0.116863  [ 3200/ 8574]\n",
      "train loss: 0.091101  [ 6400/ 8574]\n",
      "valid loss: 0.237019 \n",
      "\n",
      "Epoch 217\n",
      "-----------------------------------\n",
      "train loss: 0.013854  [    0/ 8574]\n",
      "train loss: 0.009885  [ 3200/ 8574]\n",
      "train loss: 0.022146  [ 6400/ 8574]\n",
      "valid loss: 0.237107 \n",
      "\n",
      "Epoch 218\n",
      "-----------------------------------\n",
      "train loss: 0.029068  [    0/ 8574]\n",
      "train loss: 0.008870  [ 3200/ 8574]\n",
      "train loss: 0.009530  [ 6400/ 8574]\n",
      "valid loss: 0.232064 \n",
      "\n",
      "Epoch 219\n",
      "-----------------------------------\n",
      "train loss: 0.007827  [    0/ 8574]\n",
      "train loss: 0.029315  [ 3200/ 8574]\n",
      "train loss: 0.015541  [ 6400/ 8574]\n",
      "valid loss: 0.231962 \n",
      "\n",
      "Epoch 220\n",
      "-----------------------------------\n",
      "train loss: 0.008301  [    0/ 8574]\n",
      "train loss: 0.028206  [ 3200/ 8574]\n",
      "train loss: 0.014698  [ 6400/ 8574]\n",
      "valid loss: 0.238072 \n",
      "\n",
      "Epoch 221\n",
      "-----------------------------------\n",
      "train loss: 0.013508  [    0/ 8574]\n",
      "train loss: 0.017102  [ 3200/ 8574]\n",
      "train loss: 0.016624  [ 6400/ 8574]\n",
      "valid loss: 0.235034 \n",
      "\n",
      "Epoch 222\n",
      "-----------------------------------\n",
      "train loss: 0.033819  [    0/ 8574]\n",
      "train loss: 0.024148  [ 3200/ 8574]\n",
      "train loss: 0.041204  [ 6400/ 8574]\n",
      "valid loss: 0.244551 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from cgcgnet.nn import train_step, valid_step\n",
    "\n",
    "\n",
    "NUM_EPOCHS = 500\n",
    "\n",
    "for t in range(NUM_EPOCHS):\n",
    "    print(f\"Epoch {t+1}\\n-----------------------------------\")\n",
    "    loss_train = train_step(loader_train, model, loss_fn, optimizer, DEVICE)\n",
    "    loss_valid = valid_step(loader_valid, model, loss_fn, DEVICE)\n",
    "    if stopper.step(loss_valid, model):\n",
    "        break\n",
    "stopper.load_checkpoint(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Evaluate performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we evaluate predictive performance of trained $CG^2$-Net on test data in terms of well-known regression metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cgcgnet.nn import predict_dataloader\n",
    "\n",
    "\n",
    "y_true, y_pred = predict_dataloader(model, loader_test, DEVICE)\n",
    "y_true, y_pred = y_true.flatten(), y_pred.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          mean absolute error (MAE):  0.33\n",
      "      root mean square error (RMSE):  0.46\n",
      " coefficient of determination (R^2):  0.80\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "\n",
    "\n",
    "def regression_report(y_true, y_pred):\n",
    "    metrics = [\n",
    "        (\"mean absolute error (MAE)\", mean_absolute_error(y_true, y_pred)),\n",
    "        (\n",
    "            \"root mean square error (RMSE)\",\n",
    "            mean_squared_error(y_true, y_pred, squared=False),\n",
    "        ),\n",
    "        (\"coefficient of determination (R^2)\", r2_score(y_true, y_pred)),\n",
    "    ]\n",
    "    for metric_name, metric_value in metrics:\n",
    "        print(f\"{metric_name:>35s}: {metric_value:>5.2f}\")\n",
    "\n",
    "\n",
    "regression_report(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:cgcgnet]",
   "language": "python",
   "name": "conda-env-cgcgnet-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
